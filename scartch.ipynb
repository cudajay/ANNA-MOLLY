{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from matplotlib import pyplot as plt\n",
    "from keras.callbacks import History, EarlyStopping, Callback\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "import glob as glb\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jmeow/git/ANNA-MOLLY/telemanom/telemanom\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jmeow/git/ANNA-MOLLY/telemanom/telemanom'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('telemanom')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from channel import Channel\n",
    "from helpers import Config\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cfg = Config(\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rando_data(n = 5):\n",
    "    ret = []\n",
    "    g = glb.glob(\"../data/train/*\")\n",
    "    sel = random.choice(g).split(\"/\")[-1].split(\".\")[0]\n",
    "    os.chdir('../')\n",
    "    for _ in range(n):\n",
    "        ch = Channel(cfg, sel)\n",
    "        ch.load_data()\n",
    "        ret.append(ch)\n",
    "    os.chdir('telemanom')\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = get_rando_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jmeow/git/ANNA-MOLLY/telemanom/telemanom\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pilot_X.npy\", c.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pilot_y.npy\", c.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import TimeGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560, 250, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = ch[1]\n",
    "nfeatures = c.X_train.shape[-1]\n",
    "c.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1772, 250, 55)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Input, Concatenate, Reshape, GRU\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten, RepeatVector\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Input(shape=(250, 25), name='RealData')\n",
    "Z = Input(shape=(250, 25), name='RandomData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 1\n",
    "n_seq = 25\n",
    "batch_size = 250\n",
    "hidden_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rnn(n_layers, hidden_units, output_units, name):\n",
    "    return Sequential([GRU(units=hidden_units,\n",
    "                           return_sequences=True,\n",
    "                           name=f'GRU_{i + 1}') for i in range(n_layers)] +\n",
    "                      [Dense(units=output_units,\n",
    "                             activation='sigmoid',\n",
    "                             name='OUT')], name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 10:27:06.594430: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 10:27:06.597769: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "embedder = make_rnn(n_layers=3,\n",
    "                    hidden_units=hidden_dim,\n",
    "                    output_units=hidden_dim,\n",
    "                    name='Embedder')\n",
    "recovery = make_rnn(n_layers=3,\n",
    "                    hidden_units=hidden_dim,\n",
    "                    output_units=n_seq,\n",
    "                    name='Recovery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_rnn(n_layers=3,\n",
    "                     hidden_units=hidden_dim,\n",
    "                     output_units=hidden_dim,\n",
    "                     name='Generator')\n",
    "discriminator = make_rnn(n_layers=3,\n",
    "                         hidden_units=hidden_dim,\n",
    "                         output_units=1,\n",
    "                         name='Discriminator')\n",
    "supervisor = make_rnn(n_layers=2,\n",
    "                      hidden_units=hidden_dim,\n",
    "                      output_units=hidden_dim,\n",
    "                      name='Supervisor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 10000\n",
    "gamma = 1\n",
    "mse = MeanSquaredError()\n",
    "bce = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "H = embedder(X)\n",
    "X_tilde = recovery(H)\n",
    "\n",
    "autoencoder = Model(inputs=X,\n",
    "                    outputs=X_tilde,\n",
    "                    name='Autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " RealData (InputLayer)       [(None, 250, 25)]         0         \n",
      "                                                                 \n",
      " Embedder (Sequential)       (None, 250, 10)           2540      \n",
      "                                                                 \n",
      " Recovery (Sequential)       (None, 250, 25)           2255      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,795\n",
      "Trainable params: 4,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_autoencoder_init(x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x_tilde = autoencoder(x)\n",
    "        embedding_loss_t0 = mse(x, x_tilde)\n",
    "        e_loss_0 = 10 * tf.sqrt(embedding_loss_t0)\n",
    "\n",
    "    var_list = embedder.trainable_variables + recovery.trainable_variables\n",
    "    gradients = tape.gradient(e_loss_0, var_list)\n",
    "    autoencoder_optimizer.apply_gradients(zip(gradients, var_list))\n",
    "    return tf.sqrt(embedding_loss_t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = c.X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████████████████▏                                                                                                                                        | 500/2560 [06:42<27:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Autoencoder Init', <tf.Tensor: shape=(), dtype=float32, numpy=0.19680339>, 499)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████████████████████████████████████                                                                                                       | 1000/2560 [13:06<18:55,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Autoencoder Init', <tf.Tensor: shape=(), dtype=float32, numpy=0.18925264>, 999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████████████████████████████████████████████████                                                                      | 1500/2560 [19:41<12:28,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Autoencoder Init', <tf.Tensor: shape=(), dtype=float32, numpy=0.16724482>, 1499)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 2000/2560 [26:03<07:27,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Autoencoder Init', <tf.Tensor: shape=(), dtype=float32, numpy=0.13589998>, 1999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 2500/2560 [32:22<00:47,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Autoencoder Init', <tf.Tensor: shape=(), dtype=float32, numpy=0.1714861>, 2499)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2560/2560 [33:09<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "i = 0\n",
    "for step in tqdm(range(train_steps)):\n",
    "    X_ = c.X_train[i]\n",
    "    X_ = X_.reshape(1, X_.shape[0], X_.shape[1])\n",
    "    i +=1\n",
    "    step_e_loss_t0 = train_autoencoder_init(X_)\n",
    "    if i % 500 == 0:\n",
    "        print(('Loss Autoencoder Init', step_e_loss_t0, step))\n",
    "    #with writer.as_default():\n",
    "    #    tf.summary.scalar('Loss Autoencoder Init', step_e_loss_t0, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) RealData with unsupported characters which will be renamed to realdata in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: autoencoder/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: autoencoder/assets\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save('autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "supervisor_optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_supervisor(x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        h = embedder(x)\n",
    "        h_hat_supervised = supervisor(h)\n",
    "        g_loss_s = mse(h[:, 1:, :], h_hat_supervised[:, :-1, :])\n",
    "\n",
    "    var_list = supervisor.trainable_variables\n",
    "    gradients = tape.gradient(g_loss_s, var_list)\n",
    "    supervisor_optimizer.apply_gradients(zip(gradients, var_list))\n",
    "    return g_loss_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████████████                                                                                                                                                         | 256/2560 [02:14<18:29,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=0.0002947549>, 255)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████████                                                                                                                                        | 512/2560 [04:19<16:05,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=3.1470736e-05>, 511)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████████                                                                                                                       | 768/2560 [06:29<14:09,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=2.0756506e-05>, 767)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 1024/2560 [08:37<13:07,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=1.4772981e-05>, 1023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 1280/2560 [10:46<09:33,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=4.2631465e-05>, 1279)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 1536/2560 [12:54<08:37,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=2.176747e-05>, 1535)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 1792/2560 [15:04<05:49,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=2.1587668e-05>, 1791)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 2048/2560 [17:11<04:20,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=2.5294426e-05>, 2047)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 2304/2560 [19:22<01:56,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=1.3915351e-05>, 2303)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2560/2560 [21:34<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss Generator Supervised Init', <tf.Tensor: shape=(), dtype=float32, numpy=1.0360625e-05>, 2559)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for step in tqdm(range(train_steps)):\n",
    "    X_ = c.X_train[i]\n",
    "    X_ = X_.reshape(1, X_.shape[0], X_.shape[1])\n",
    "    i +=1\n",
    "    step_g_loss_s = train_supervisor(X_)\n",
    "    if i % int(train_steps/10) == 0:\n",
    "        print(('Loss Generator Supervised Init', step_g_loss_s, step))\n",
    "    #with writer.as_default():\n",
    "    #    tf.summary.scalar('Loss Generator Supervised Init', step_g_loss_s, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) GRU_1_input with unsupported characters which will be renamed to gru_1_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: supervisor/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: supervisor/assets\n"
     ]
    }
   ],
   "source": [
    "supervisor.save(\"supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AdversarialNetSupervised\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " RandomData (InputLayer)     [(None, 250, 25)]         0         \n",
      "                                                                 \n",
      " Generator (Sequential)      (None, 250, 10)           2540      \n",
      "                                                                 \n",
      " Supervisor (Sequential)     (None, 250, 10)           1430      \n",
      "                                                                 \n",
      " Discriminator (Sequential)  (None, 250, 1)            1991      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,961\n",
      "Trainable params: 5,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "E_hat = generator(Z)\n",
    "H_hat = supervisor(E_hat)\n",
    "Y_fake = discriminator(H_hat)\n",
    "\n",
    "adversarial_supervised = Model(inputs=Z,\n",
    "                               outputs=Y_fake,\n",
    "                               name='AdversarialNetSupervised')\n",
    "adversarial_supervised.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AdversarialNet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " RandomData (InputLayer)     [(None, 250, 25)]         0         \n",
      "                                                                 \n",
      " Generator (Sequential)      (None, 250, 10)           2540      \n",
      "                                                                 \n",
      " Discriminator (Sequential)  (None, 250, 1)            1991      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,531\n",
      "Trainable params: 4,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Y_fake_e = discriminator(E_hat)\n",
    "\n",
    "adversarial_emb = Model(inputs=Z,\n",
    "                    outputs=Y_fake_e,\n",
    "                    name='AdversarialNet')\n",
    "adversarial_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SyntheticData\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " RandomData (InputLayer)     [(None, 250, 25)]         0         \n",
      "                                                                 \n",
      " Generator (Sequential)      (None, 250, 10)           2540      \n",
      "                                                                 \n",
      " Supervisor (Sequential)     (None, 250, 10)           1430      \n",
      "                                                                 \n",
      " Recovery (Sequential)       (None, 250, 25)           2255      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,225\n",
      "Trainable params: 6,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_hat = recovery(H_hat)\n",
    "synthetic_data = Model(inputs=Z,\n",
    "                       outputs=X_hat,\n",
    "                       name='SyntheticData')\n",
    "synthetic_data.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_moment_loss(y_true, y_pred):\n",
    "    y_true_mean, y_true_var = tf.nn.moments(x=y_true, axes=[0])\n",
    "    y_pred_mean, y_pred_var = tf.nn.moments(x=y_pred, axes=[0])\n",
    "    g_loss_mean = tf.reduce_mean(tf.abs(y_true_mean - y_pred_mean))\n",
    "    g_loss_var = tf.reduce_mean(tf.abs(tf.sqrt(y_true_var + 1e-6) - tf.sqrt(y_pred_var + 1e-6)))\n",
    "    return g_loss_mean + g_loss_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DiscriminatorReal\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " RealData (InputLayer)       [(None, 250, 25)]         0         \n",
      "                                                                 \n",
      " Embedder (Sequential)       (None, 250, 10)           2540      \n",
      "                                                                 \n",
      " Discriminator (Sequential)  (None, 250, 1)            1991      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,531\n",
      "Trainable params: 4,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Y_real = discriminator(H)\n",
    "discriminator_model = Model(inputs=X,\n",
    "                            outputs=Y_real,\n",
    "                            name='DiscriminatorReal')\n",
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = Adam()\n",
    "discriminator_optimizer = Adam()\n",
    "embedding_optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_generator(x, z):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_fake = adversarial_supervised(z)\n",
    "        generator_loss_unsupervised = bce(y_true=tf.ones_like(y_fake),\n",
    "                                          y_pred=y_fake)\n",
    "\n",
    "        y_fake_e = adversarial_emb(z)\n",
    "        generator_loss_unsupervised_e = bce(y_true=tf.ones_like(y_fake_e),\n",
    "                                            y_pred=y_fake_e)\n",
    "        h = embedder(x)\n",
    "        h_hat_supervised = supervisor(h)\n",
    "        generator_loss_supervised = mse(h[:, 1:, :], h_hat_supervised[:, 1:, :])\n",
    "\n",
    "        x_hat = synthetic_data(z)\n",
    "        generator_moment_loss = get_generator_moment_loss(x, x_hat)\n",
    "\n",
    "        generator_loss = (generator_loss_unsupervised +\n",
    "                          generator_loss_unsupervised_e +\n",
    "                          100 * tf.sqrt(generator_loss_supervised) +\n",
    "                          100 * generator_moment_loss)\n",
    "\n",
    "    var_list = generator.trainable_variables + supervisor.trainable_variables\n",
    "    gradients = tape.gradient(generator_loss, var_list)\n",
    "    generator_optimizer.apply_gradients(zip(gradients, var_list))\n",
    "    return generator_loss_unsupervised, generator_loss_supervised, generator_moment_loss\n",
    "\n",
    "@tf.function\n",
    "def train_embedder(x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        h = embedder(x)\n",
    "        h_hat_supervised = supervisor(h)\n",
    "        generator_loss_supervised = mse(h[:, 1:, :], h_hat_supervised[:, 1:, :])\n",
    "\n",
    "        x_tilde = autoencoder(x)\n",
    "        embedding_loss_t0 = mse(x, x_tilde)\n",
    "        e_loss = 10 * tf.sqrt(embedding_loss_t0) + 0.1 * generator_loss_supervised\n",
    "\n",
    "    var_list = embedder.trainable_variables + recovery.trainable_variables\n",
    "    gradients = tape.gradient(e_loss, var_list)\n",
    "    embedding_optimizer.apply_gradients(zip(gradients, var_list))\n",
    "    return tf.sqrt(embedding_loss_t0)\n",
    "\n",
    "@tf.function\n",
    "def get_discriminator_loss(x, z):\n",
    "    y_real = discriminator_model(x)\n",
    "    discriminator_loss_real = bce(y_true=tf.ones_like(y_real),\n",
    "                                  y_pred=y_real)\n",
    "\n",
    "    y_fake = adversarial_supervised(z)\n",
    "    discriminator_loss_fake = bce(y_true=tf.zeros_like(y_fake),\n",
    "                                  y_pred=y_fake)\n",
    "\n",
    "    y_fake_e = adversarial_emb(z)\n",
    "    discriminator_loss_fake_e = bce(y_true=tf.zeros_like(y_fake_e),\n",
    "                                    y_pred=y_fake_e)\n",
    "    return (discriminator_loss_real +\n",
    "            discriminator_loss_fake +\n",
    "            gamma * discriminator_loss_fake_e)\n",
    "\n",
    "@tf.function\n",
    "def train_discriminator(x, z):\n",
    "    with tf.GradientTape() as tape:\n",
    "        discriminator_loss = get_discriminator_loss(x, z)\n",
    "\n",
    "    var_list = discriminator.trainable_variables\n",
    "    gradients = tape.gradient(discriminator_loss, var_list)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients, var_list))\n",
    "    return discriminator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Idata:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.i = 0\n",
    "        \n",
    "    def __next__(self):\n",
    "        ret = self.data[self.i]\n",
    "        self.i += 1\n",
    "        if self.i >= len(self.data):\n",
    "            self.i = 0\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = Idata(c.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idata = iter(c.X_train)\n",
    "idata2 = iter(c.X_train)\n",
    "step_g_loss_u = step_g_loss_s = step_g_loss_v = step_e_loss_t0 = step_d_loss = 0\n",
    "for step in range(1000):\n",
    "    # Train generator (twice as often as discriminator)\n",
    "    j = 0\n",
    "    for kk in range(2):\n",
    "        print(step,j)\n",
    "        X_ = next(idata)\n",
    "        X_ = X_.reshape(1, X_.shape[0], X_.shape[1]).astype('float32')\n",
    "        Z_ = np.random.rand(1,250,25).astype('float32')\n",
    "\n",
    "        # Train generator\n",
    "        step_g_loss_u, step_g_loss_s, step_g_loss_v = train_generator(X_, Z_)\n",
    "        # Train embedder\n",
    "        step_e_loss_t0 = train_embedder(X_)\n",
    "\n",
    "    X_ = next(idata2)\n",
    "    X_ = X_.reshape(1, X_.shape[0], X_.shape[1])\n",
    "    Z_ = np.random.rand(1,250,25).astype('float32')\n",
    "    step_d_loss = get_discriminator_loss(X_, Z_)\n",
    "    if step_d_loss > 0.15:\n",
    "        step_d_loss = train_discriminator(X_, Z_)\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f'{step:6,.0f} | d_loss: {step_d_loss:6.4f} | g_loss_u: {step_g_loss_u:6.4f} | '\n",
    "              f'g_loss_s: {step_g_loss_s:6.4f} | g_loss_v: {step_g_loss_v:6.4f} | e_loss_t0: {step_e_loss_t0:6.4f}')\n",
    "\n",
    "    #with writer.as_default():\n",
    "    #    tf.summary.scalar('G Loss S', step_g_loss_s, step=step)\n",
    "    #    tf.summary.scalar('G Loss U', step_g_loss_u, step=step)\n",
    "    #    tf.summary.scalar('G Loss V', step_g_loss_v, step=step)\n",
    "    #    tf.summary.scalar('E Loss T0', step_e_loss_t0, step=step)\n",
    "    #    tf.summary.scalar('D Loss', step_d_loss, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) RandomData with unsupported characters which will be renamed to randomdata in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_6_layer_call_fn, gru_cell_6_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn, gru_cell_7_layer_call_and_return_conditional_losses, gru_cell_8_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: synthetic_data/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: synthetic_data/assets\n"
     ]
    }
   ],
   "source": [
    "synthetic_data.save('synthetic_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3484108 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.17436473,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.19344707,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.53209129,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.89963421,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.88894542,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = []\n",
    "for i in range(10):\n",
    "    Z_ = np.random.rand(1,250,25).astype('float32')\n",
    "    d = synthetic_data(Z_)\n",
    "    generated_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda activate meow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 19:55:55.296322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 19:55:55.299395: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "reloaded_obj = tf.saved_model.load(\"synthetic_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = []\n",
    "for i in range(10):\n",
    "    Z_ = np.random.rand(1,250,25).astype('float32')\n",
    "    d = reloaded_obj(Z_)\n",
    "    generated_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([250])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data[0][0][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = c.X_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [-1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [-1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [-1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [-1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [-1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0b0da588e0>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(generated_data[0][0][:,15])\n",
    "#plt.plot(cc[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meow2",
   "language": "python",
   "name": "meow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
